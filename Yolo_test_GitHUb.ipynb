{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Label Conversion and Visualization\n",
    "\n",
    "This script demonstrates how to convert label files from LabelMe to YOLO format, and then visualize the results using matplotlib. The following libraries are used:\n",
    "\n",
    "- `labelme2yolo`: A module to convert LabelMe annotations to YOLO format.\n",
    "- `json` and `os`: Built-in Python libraries for handling JSON data and operating system functionalities, respectively.\n",
    "- `ultralytics.YOLO`: A library to work with YOLO (You Only Look Once) models.\n",
    "- `matplotlib.pyplot`: A plotting library used for visualization.\n",
    "- `PIL.Image`: A library for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelme2yolo\n",
    "import json\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib.pyplot import figure\n",
    "from PIL import Image\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON File Processing and Image Path Modification\n",
    "\n",
    "This script processes JSON files in a specified folder to modify the `imagePath` attribute. The following steps are performed:\n",
    "\n",
    "1. Iterate over all JSON files in the specified folder.\n",
    "2. Open and read each JSON file.\n",
    "3. Check if the `imagePath` attribute exists.\n",
    "4. Modify the `imagePath` attribute to only include the filename, removing any preceding path.\n",
    "5. Save the modified data back to the JSON file.\n",
    "6. Print the contents of a specific JSON file to verify the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'Intersecting_Batches-4'\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.json'):  # Check if the file is a JSON file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Check if 'ImagePath' exists in the dictionary and modify it\n",
    "        if 'imagePath' in data:\n",
    "            data['imagePath'] = data['imagePath'].split('/')[-1]\n",
    "\n",
    "        # Save the modified data back to the JSON file\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "print(\"Processing complete. Image paths have been updated.\")\n",
    "\n",
    "file_path = 'Intersecting_Batches-4/tile_0_30.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the contents of the JSON file\n",
    "data['imagePath']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "# Print the contents of the JSON file\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIFF to JPEG Conversion Script\n",
    "\n",
    "This script converts all TIFF files in a specified input directory to JPEG format and saves them to an output directory. The following steps are performed:\n",
    "\n",
    "1. Check if the output directory exists, and create it if it doesn't.\n",
    "2. Iterate through all files in the input directory.\n",
    "3. For each TIFF file, open and convert it to JPEG format.\n",
    "4. Save the converted JPEG file to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def convert_tif_to_jpeg(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Converts all TIFF files in the input directory to JPEG format,\n",
    "    saving them to the output directory.\n",
    "    \"\"\"\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".tif\") or filename.endswith(\".tiff\"):\n",
    "            # Construct the full file path\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, filename.rsplit('.', 1)[0] + '.jpg')\n",
    "            \n",
    "            # Open the image, convert and save as JPEG\n",
    "            try:\n",
    "                with Image.open(input_path) as img:\n",
    "                    img.convert('RGB').save(output_path, \"JPEG\")\n",
    "                #print(f\"Converted {filename} to JPEG and saved to {output_path}\")\n",
    "            except Exception as e:\n",
    "                #print(f\"Failed to convert {filename}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "input_directory = 'Intersecting_Batches-4'\n",
    "output_directory = 'Intersecting_Batches-4/jpeg'\n",
    "convert_tif_to_jpeg(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme2yolo --json_dir ./Intersecting_Batches-4 --val_size 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for balanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Extraction and Visualization Script\n",
    "\n",
    "This script scans a directory for `.txt` files, extracts the first token from each line (assumed to be a label), counts the occurrences of each label, and plots a bar chart to visualize the label counts. The following steps are performed:\n",
    "\n",
    "1. Traverse the directory to find all `.txt` files.\n",
    "2. For each `.txt` file, extract the first token from each line and count its occurrences.\n",
    "3. Print the count of each label.\n",
    "4. Plot a bar chart of the label counts using `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def scan_and_extract_labels_from_txt(directory):\n",
    "    label_counts = Counter()\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        for line in f:\n",
    "                            label = line.strip().split()[0]\n",
    "                            label_counts[label] += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Print the count of each label\n",
    "    for label, count in label_counts.items():\n",
    "        print(f\"Label {label}: {count}\")\n",
    "\n",
    "    return label_counts\n",
    "\n",
    "# Replace 'your_directory_path_here' with the path to your directory\n",
    "directory_path = 'Post_Event_Grids_In_JPEG/YOLODataset/labels'\n",
    "label_counts = scan_and_extract_labels_from_txt(directory_path)\n",
    "\n",
    "# Plotting the bar chart\n",
    "labels, counts = zip(*label_counts.items())\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, counts, color='skyblue')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Label Counts in Dataset')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation Pipeline\n",
    "\n",
    "This script defines an image augmentation pipeline using the `albumentations` library. The pipeline includes various augmentations such as horizontal flip, vertical flip, random rotation, brightness/contrast adjustment, Gaussian noise, and blur. The following steps are performed:\n",
    "\n",
    "1. Import necessary augmentation functions from `albumentations`.\n",
    "2. Define a function to create and return a composition of augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import Compose, HorizontalFlip, VerticalFlip, RandomRotate90, RandomBrightnessContrast, GaussNoise, Blur\n",
    "\n",
    "def get_augmentation_pipeline():\n",
    "    \"\"\"Defines and returns an augmentation pipeline with multiple augmentations.\"\"\"\n",
    "    return Compose([\n",
    "        HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "        RandomRotate90(p=0.5),\n",
    "        RandomBrightnessContrast(p=0.5),\n",
    "        GaussNoise(p=0.2),\n",
    "        Blur(blur_limit=3, p=0.2),\n",
    "        # Add more augmentations here as needed.\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading, Saving, and Augmentation Functions\n",
    "\n",
    "This script provides functions to load an image, save an image, and apply an augmentation pipeline to an image using `opencv` and `albumentations` libraries. The following steps are performed:\n",
    "\n",
    "1. Load an image from a given path.\n",
    "2. Save an image to a given path.\n",
    "3. Apply an augmentation pipeline to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Loads an image from a given path.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def save_image(image, path):\n",
    "    \"\"\"Saves an image to a given path.\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(path, image)\n",
    "\n",
    "\n",
    "def augment_image(image, augmentation_pipeline):\n",
    "    \"\"\"Applies the augmentation pipeline to an image.\"\"\"\n",
    "    augmented = augmentation_pipeline(image=image)\n",
    "    return augmented['image']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation Pipeline\n",
    "\n",
    "This script defines an image augmentation pipeline using the `albumentations` library. The pipeline includes various augmentations such as horizontal flip, vertical flip, random rotation, brightness/contrast adjustment, Gaussian noise, and blur. The following steps are performed:\n",
    "\n",
    "1. Import necessary augmentation functions from `albumentations`.\n",
    "2. Define a function to create and return a composition of augmentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Assuming the load_image and save_image functions are already defined as per previous examples.\n",
    "\n",
    "def process_directory(input_dir, output_dir):\n",
    "    \"\"\"Processes all images in the input directory with augmentations and saves them to the output directory.\"\"\"\n",
    "    # Make sure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    augmentation_pipeline = get_augmentation_pipeline()\n",
    "\n",
    "    # Iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\")):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"aug_{filename}\")\n",
    "            \n",
    "            try:\n",
    "                # Load the image\n",
    "                image = load_image(input_path)\n",
    "                # Apply augmentations\n",
    "                augmented_image = augment_image(image, augmentation_pipeline)\n",
    "                # Save the augmented image\n",
    "                save_image(augmented_image, output_path)\n",
    "                print(f\"Processed and saved {filename} as {output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_directory = 'Intersecting_Batches-4/jpeg'\n",
    "    output_directory = 'Intersecting_Batches-4/jpeg'\n",
    "    process_directory(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'datasets/images'\n",
    "labels_path = 'datasets/labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Model Initialization\n",
    "\n",
    "This line initializes a YOLOv8 model by loading the pre-trained weights from the \"yolov8s.pt\" file, allowing for object detection and image segmentation tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8s.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This line trains the YOLOv8 model using the dataset specified in the `dataset.yaml` file. The training process runs for 12 epochs with an image size of 512x512 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data='./dataset.yaml', epochs=12, imgsz=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages for Hyperparameter Tuning\n",
    "\n",
    "This script imports necessary functions for hyperparameter tuning from the `hyperopt` library. The imported functions include:\n",
    "\n",
    "- `fmin`: Function to minimize the objective function.\n",
    "- `tpe`: Tree-structured Parzen Estimator, a sequential model-based optimization algorithm.\n",
    "- `hp`: Hyperparameter search space.\n",
    "- `STATUS_OK`: Status flag for successful trials.\n",
    "- `Trials`: Object to keep track of the optimization process and results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages for hyperparameter tuning \n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /Users/elenalickel/Desktop/EY_Challengev2/venv/lib/python3.8/site-packages/ultralytics/models/yolo/classify/train.py --img 512 --batch 16 --epochs 30 --data dataset.yaml --weights /runs/detect/train23/weights/last.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Ray Tune\n",
    "\n",
    "This script performs hyperparameter tuning using the `ray[tune]` library. The process involves defining a search space for hyperparameters and running multiple trials to find the optimal configuration. The following steps are performed:\n",
    "\n",
    "1. Import necessary modules from `ray.tune`.\n",
    "2. Define a function `train_model_with_ray_tune` to train the model with parameters provided by Ray Tune.\n",
    "3. Define the search space for hyperparameters.\n",
    "4. Start the hyperparameter tuning process with `tune.run`.\n",
    "5. Extract and print the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"ray[tune]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_model_with_ray_tune(config):\n",
    "    # Extract parameters from the config provided by Ray Tune\n",
    "    lr = config[\"lr\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    \n",
    "    # Call your existing training function with parameters from Ray Tune\n",
    "    train_results = train_model_with_dynamic_config(\n",
    "        ckpt_path=latest_ckpt_path,  # Make sure latest_ckpt_path is defined\n",
    "        epochs=30,  # Consider making this a tunable parameter as well\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    # Report the validation metric back to Ray Tune\n",
    "    # Ensure your training function returns a dictionary with \"validation_metric\"\n",
    "    tune.report(validation_metric=train_results['validation_metric'])\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64])\n",
    "}\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "analysis = tune.run(\n",
    "    train_model_with_ray_tune,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},  # Adjust resources per your availability\n",
    "    config=search_space,\n",
    "    num_samples=100,  # Number of trials to run\n",
    "    metric=\"validation_metric\",  # Name of the metric to optimize\n",
    "    mode=\"max\",  # \"max\" if higher metric is better, \"min\" otherwise\n",
    ")\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "best_config = analysis.best_config\n",
    "best_lr = best_config[\"lr\"]\n",
    "best_batch_size = best_config[\"batch_size\"]\n",
    "\n",
    "print(f\"Best hyperparameters found were: lr = {best_lr}, batch_size = {best_batch_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the ray module\n",
    "!pip install ray\n",
    "\n",
    "import numpy as np\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "def train_model_with_dynamic_config(ckpt_path, epochs, lr, batch_size):\n",
    "    # Placeholder for actual training logic\n",
    "    # Example return dictionary with a validation metric\n",
    "    return {\"validation_metric\": np.random.random()}\n",
    "\n",
    "def train_model_with_ray_tune(config):\n",
    "    # Extract parameters from the config provided by Ray Tune\n",
    "    lr = config[\"lr\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    \n",
    "    # Assuming latest_ckpt_path is a global variable or defined elsewhere in your script\n",
    "    global latest_ckpt_path\n",
    "    latest_ckpt_path = \"path/to/latest/checkpoint\"\n",
    "    \n",
    "    # Call your existing training function with parameters from Ray Tune\n",
    "    train_results = train_model_with_dynamic_config(\n",
    "        ckpt_path=latest_ckpt_path,\n",
    "        epochs=30,  # Consider making this a tunable parameter as well\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    \n",
    "    # Report the validation metric back to Ray Tune\n",
    "    tune.report(validation_metric=train_results['validation_metric'])\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\": tune.choice([8, 16, 32, 64])\n",
    "}\n",
    "\n",
    "# Define a scheduler for early stopping\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"validation_metric\",\n",
    "    mode=\"max\",\n",
    "    max_t=30,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "analysis = tune.run(\n",
    "    train_model_with_ray_tune,\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},  # Adjust resources per your availability\n",
    "    config=search_space,\n",
    "    num_samples=100,  # Number of trials to run\n",
    "    metric=\"validation_metric\",  # Name of the metric to optimize\n",
    "    mode=\"max\",  # \"max\" if higher metric is better, \"min\" otherwise\n",
    "    scheduler=scheduler\n",
    ")\n",
    "\n",
    "# Extract the best hyperparameters\n",
    "best_config = analysis.best_config\n",
    "best_lr = best_config[\"lr\"]\n",
    "best_batch_size = best_config[\"batch_size\"]\n",
    "\n",
    "print(f\"Best hyperparameters found were: lr = {best_lr}, batch_size = {best_batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Tuned Parameters\n",
    "\n",
    "After determining the best hyperparameters via tuning, the model is trained using these optimal settings. The following steps are performed:\n",
    "\n",
    "1. Train the model using the best parameters found during hyperparameter tuning.\n",
    "2. Track the training results with an experiment tracking system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "\n",
    "# Assuming train_results is a dictionary or similar structure containing your results and metrics\n",
    "\n",
    "# After determining the best parameters via tuning\n",
    "train_results = train_model_with_dynamic_config(\n",
    "    ckpt_path=find_latest_checkpoint(checkpoint_dir),\n",
    "    epochs=best_params['epochs'],\n",
    "    lr=best_params['lr'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    # Potentially other parameters tuned or adjusted based on past performance\n",
    ")\n",
    "\n",
    "# Track the results with your experiment tracking system\n",
    "track_experiment_results(train_results)\n",
    "\n",
    "# Display the training results image\n",
    "plt.figure(figsize=(15, 10), dpi=80)\n",
    "# Reading the image\n",
    "results = img.imread('runs/detect/train_results/results.png')\n",
    "# Displaying the image\n",
    "plt.imshow(results)\n",
    "plt.axis('off')  # Hide the axes for better image display\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Image Files in a Folder\n",
    "\n",
    "This script lists all image files in a specified folder. It supports various image file extensions such as `.png`, `.jpg`, `.jpeg`, `.gif`, and `.bmp`. The following steps are performed:\n",
    "\n",
    "1. Import necessary modules `os` and `glob`.\n",
    "2. Define a function `list_images` to scan the folder for image files and collect their paths.\n",
    "3. Specify the folder path to scan for images.\n",
    "4. Print the list of image paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def list_images(folder_path):\n",
    "    # List to hold all image paths\n",
    "    image_paths = []\n",
    "    \n",
    "    # Supported image extensions\n",
    "    image_extensions = ['*.png', '*.jpg', '*.jpeg', '*.gif', '*.bmp']\n",
    "    \n",
    "    # Scan through the folder for each image extension\n",
    "    for extension in image_extensions:\n",
    "        # Use glob to find all files in folder_path with the current extension\n",
    "        for image_path in glob.glob(os.path.join(folder_path, extension)):\n",
    "            # Add the image path to the list\n",
    "            image_paths.append(image_path)\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# Replace 'your/folder/path' with the actual folder path you want to scan\n",
    "folder_path = 'datasets/images/test'\n",
    "images = list_images(folder_path)\n",
    "print(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model\n",
    "\n",
    "This line loads a pre-trained YOLOv8 model using the weights from the specified path. The model is ready for inference or further training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "model = YOLO('./runs/detect/train_results/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Generate Output for Submission Data\n",
    "\n",
    "This performs predictions on images in the submission data directory using the YOLO model and generates output text files with bounding box information. The script follows these steps:\n",
    "\n",
    "1. Define the decoding of predictions according to class names in the `.yaml` file.\n",
    "2. Set the directory paths for input images and output results.\n",
    "3. Create the results directory if it doesn't exist.\n",
    "4. Loop through each image file in the submission data directory and perform predictions.\n",
    "5. Decode the predictions and save the results to text files in the results directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the submission data for zip\n",
    "# Decoding according to the .yaml file class names order\n",
    "decoding_of_predictions ={2: 'undamagedcommercialbuilding', 0: 'undamagedresidentialbuilding', 1: 'damagedresidentialbuilding', 3: 'damagedcommercialbuilding'}\n",
    "\n",
    "directory = 'Submission data'\n",
    "# Directory to store outputs\n",
    "results_directory = 'Validation_Data_Results'\n",
    "\n",
    "# Create submission directory if it doesn't exist\n",
    "if not os.path.exists(results_directory):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the current object is a file and ends with .jpeg\n",
    "    if os.path.isfile(os.path.join(directory, filename)) and filename.lower().endswith('.jpg'):\n",
    "        # Perform operations on the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        print(file_path)\n",
    "        print(\"Making a prediction on \", filename)\n",
    "        results = model.predict(file_path, save=True, iou=0.5, save_txt=True, conf=0.25)\n",
    "        \n",
    "        for r in results:\n",
    "            conf_list = r.boxes.conf.numpy().tolist()\n",
    "            clss_list = r.boxes.cls.numpy().tolist()\n",
    "            original_list = clss_list\n",
    "            updated_list = []\n",
    "            for element in original_list:\n",
    "                 updated_list.append(decoding_of_predictions[int(element)])\n",
    "\n",
    "        bounding_boxes = r.boxes.xyxy.numpy()\n",
    "        confidences = conf_list\n",
    "        class_names = updated_list\n",
    "\n",
    "        # Check if bounding boxes, confidences and class names match\n",
    "        if len(bounding_boxes) != len(confidences) or len(bounding_boxes) != len(class_names):\n",
    "            print(\"Error: Number of bounding boxes, confidences, and class names should be the same.\")\n",
    "            continue\n",
    "        text_file_name = os.path.splitext(filename)[0]\n",
    "        # Creating a new .txt file for each image in the submission_directory\n",
    "        with open(os.path.join(results_directory, f\"{text_file_name}.txt\"), \"w\") as file:\n",
    "            for i in range(len(bounding_boxes)):\n",
    "                # Get coordinates of each bounding box\n",
    "                left, top, right, bottom = bounding_boxes[i]\n",
    "                # Write content to file in desired format\n",
    "                file.write(f\"{class_names[i]} {confidences[i]} {left} {top} {right} {bottom}\\n\")\n",
    "        print(\"Output files generated successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
